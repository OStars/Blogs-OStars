## QLora

[OLora 及模型量化背景知识介绍](https://zhuanlan.zhihu.com/p/666234324)

### 为什么 lora 增加了计算量，但是实际训练速度还会变快？

1. 只更新了部分参数：比如 LoRA 原论文就选择只更新 Self Attention 的参数，实际使用时我们还可以选择只更新部分层的参数；
2. 减少了通信时间：由于更新的参数量变少了，所以（尤其是多卡训练时）要传输的数据量也变少了，从而减少了传输时间；
3. 采用了各种低精度加速技术，如FP16、FP8或者INT8量化等。

### 为什么 lora 能够 work？

> 以往的一些结果（比如[《Exploring Universal Intrinsic Task Subspace via Prompt Tuning》](https://papers.cool/arxiv/2110.07867)）显示，尽管预训练模型的参数量很大，但每个下游任务对应的本征维度（Intrinsic Dimension）并不大，换句话说，理论上我们可以微调非常小的参数量，就能在下游任务取得不错的效果。

与本征维度相关的一些见解 (理论)：

1. 预训练模型能够隐式地降低模型在 NLP 各个任务的本征维度，预训练质量越高，模型本征维度越低
2. 模型越大本征维度越小，即越强的模型本征维度越低。
3. 本征维度越低，泛化性能越好。